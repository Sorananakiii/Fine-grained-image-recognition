{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport re\nimport pandas as pd\npd.set_option('display.max_colwidth', 200)\n\nimport tarfile\nimport scipy.io\nfrom collections import defaultdict\n\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\n# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/fgvc-aircraft/train.csv')\nval = pd.read_csv('../input/fgvc-aircraft/val.csv')\ntest = pd.read_csv('../input/fgvc-aircraft/test.csv')\ntrain.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"      filename  Classes  Labels\n0  1025794.jpg  707-320       0\n1  1340192.jpg  707-320       0\n2  0056978.jpg  707-320       0\n3  0698580.jpg  707-320       0\n4  0450014.jpg  707-320       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Classes</th>\n      <th>Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1025794.jpg</td>\n      <td>707-320</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1340192.jpg</td>\n      <td>707-320</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0056978.jpg</td>\n      <td>707-320</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0698580.jpg</td>\n      <td>707-320</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0450014.jpg</td>\n      <td>707-320</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpath = \"../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images\"\ntrain_paths = train.filename.apply(lambda x: os.path.join(tpath, x))\ntrain_paths.values","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"array(['../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/1025794.jpg',\n       '../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/1340192.jpg',\n       '../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/0056978.jpg',\n       ...,\n       '../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/0472681.jpg',\n       '../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/1597829.jpg',\n       '../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/0197891.jpg'],\n      dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n\n# convert to one-hot-encoding-labels\ntrain_labels = to_categorical(train.Labels)\ntrain_labels.shape","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"(3334, 100)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpath = \"../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images\"\nval_paths = val.filename.apply(lambda x: os.path.join(tpath, x))\nval_paths.values","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"array(['../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/0481847.jpg',\n       '../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/0810608.jpg',\n       '../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/1514481.jpg',\n       ...,\n       '../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/1340345.jpg',\n       '../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/0765754.jpg',\n       '../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/1594714.jpg'],\n      dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert to one-hot-encoding-labels\nval_labels = to_categorical(val.Labels)\nval_labels.shape","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"(3333, 100)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpath = \"../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images\"\ntest_paths = test.filename.apply(lambda x: os.path.join(tpath, x))\ntest_paths.values","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"array(['../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/1514522.jpg',\n       '../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/0747566.jpg',\n       '../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/1008575.jpg',\n       ...,\n       '../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/0329381.jpg',\n       '../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/0523192.jpg',\n       '../input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/0810303.jpg'],\n      dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(filename, label=None, image_size=(299, 299)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\n\ntrain_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(2048)\n    .batch(batch_size)\n    .prefetch(AUTO)\n)\n\nval_dataset = (tf.data.Dataset\n        .from_tensor_slices((val_paths, val_labels))\n        .map(decode_image, num_parallel_calls=AUTO)\n        .batch(batch_size)\n)\n\ntest_dataset = (tf.data.Dataset\n        .from_tensor_slices(test_paths)\n        .map(decode_image, num_parallel_calls=AUTO)\n        .batch(batch_size)\n)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import ResNet101\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\n\n# from efficientnet.tfkeras import EfficientNetB2\n\nmodel = tf.keras.Sequential([\n        ResNet101(weights = 'imagenet', \n                       include_top = False,\n                       input_shape = (299, 299, 3)),\n        GlobalAveragePooling2D(),\n        Dense(1024, activation = 'relu'),\n        Dropout(0.25),\n        Dense(512, activation = 'relu'),\n        Dropout(0.25),\n        Dense(100, activation = 'softmax')\n])\n    \nmodel.compile(optimizer = 'sgd',\n              loss = 'categorical_crossentropy',\n              metrics = ['accuracy'])\n    \nmodel.summary()","execution_count":11,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n171450368/171446536 [==============================] - 3s 0us/step\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet101 (Model)            (None, 10, 10, 2048)      42658176  \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 2048)              0         \n_________________________________________________________________\ndense (Dense)                (None, 1024)              2098176   \n_________________________________________________________________\ndropout (Dropout)            (None, 1024)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               524800    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 100)               51300     \n=================================================================\nTotal params: 45,332,452\nTrainable params: 45,227,108\nNon-trainable params: 105,344\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Train_model(model, batch_size, EPOCHS):\n    n_steps = train_labels.shape[0] // batch_size\n    EPOCHS = EPOCHS\n    \n    Model = model\n    history = Model.fit(train_dataset, \n                    steps_per_epoch = n_steps,\n                    epochs = EPOCHS,\n                    validation_data = val_dataset,\n                    verbose = 1)\n    return Model","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nEPOCHS = 50\n\ndef check(x, y):\n    if x == y:\n        return 1\n    else:\n        return 0\n    \nprint('Training')\nmodel = Train_model(model, batch_size, EPOCHS)\npred = model.predict(test_dataset, verbose=1)\n    \ntest['Prediction'] = pred.argmax(axis=1)\ntest['Score'] = test.apply(lambda x: check(x['Prediction'], x['Labels']), axis=1)\nprint('Test accuracy on iterations is ', 100 * test.Score.sum() / test.shape[0])","execution_count":13,"outputs":[{"output_type":"stream","text":"Training\nEpoch 1/50\n104/104 [==============================] - 89s 852ms/step - loss: 4.5259 - accuracy: 0.0421 - val_loss: 4.6116 - val_accuracy: 0.0396\nEpoch 2/50\n104/104 [==============================] - 85s 815ms/step - loss: 4.0449 - accuracy: 0.1106 - val_loss: 4.6696 - val_accuracy: 0.0099\nEpoch 3/50\n104/104 [==============================] - 85s 817ms/step - loss: 3.3164 - accuracy: 0.2215 - val_loss: 4.7139 - val_accuracy: 0.0120\nEpoch 4/50\n104/104 [==============================] - 86s 825ms/step - loss: 2.4632 - accuracy: 0.3900 - val_loss: 4.7622 - val_accuracy: 0.0147\nEpoch 5/50\n104/104 [==============================] - 84s 812ms/step - loss: 1.8267 - accuracy: 0.5108 - val_loss: 4.6597 - val_accuracy: 0.0159\nEpoch 6/50\n104/104 [==============================] - 84s 808ms/step - loss: 1.3455 - accuracy: 0.6400 - val_loss: 4.2390 - val_accuracy: 0.0477\nEpoch 7/50\n104/104 [==============================] - 86s 822ms/step - loss: 0.9722 - accuracy: 0.7290 - val_loss: 3.1462 - val_accuracy: 0.2220\nEpoch 8/50\n104/104 [==============================] - 85s 815ms/step - loss: 0.7249 - accuracy: 0.8038 - val_loss: 2.5116 - val_accuracy: 0.3501\nEpoch 9/50\n104/104 [==============================] - 85s 822ms/step - loss: 0.5091 - accuracy: 0.8672 - val_loss: 1.8672 - val_accuracy: 0.4977\nEpoch 10/50\n104/104 [==============================] - 84s 806ms/step - loss: 0.3727 - accuracy: 0.9029 - val_loss: 1.7504 - val_accuracy: 0.5479\nEpoch 11/50\n104/104 [==============================] - 89s 852ms/step - loss: 0.2789 - accuracy: 0.9288 - val_loss: 1.4485 - val_accuracy: 0.6190\nEpoch 12/50\n104/104 [==============================] - 84s 810ms/step - loss: 0.2084 - accuracy: 0.9459 - val_loss: 1.5230 - val_accuracy: 0.6061\nEpoch 13/50\n104/104 [==============================] - 85s 818ms/step - loss: 0.1537 - accuracy: 0.9648 - val_loss: 1.4033 - val_accuracy: 0.6343\nEpoch 14/50\n104/104 [==============================] - 85s 819ms/step - loss: 0.1240 - accuracy: 0.9715 - val_loss: 1.2707 - val_accuracy: 0.6718\nEpoch 15/50\n104/104 [==============================] - 84s 812ms/step - loss: 0.1014 - accuracy: 0.9805 - val_loss: 1.4211 - val_accuracy: 0.6379\nEpoch 16/50\n104/104 [==============================] - 85s 821ms/step - loss: 0.0772 - accuracy: 0.9862 - val_loss: 1.2689 - val_accuracy: 0.6784\nEpoch 17/50\n104/104 [==============================] - 85s 814ms/step - loss: 0.0607 - accuracy: 0.9889 - val_loss: 1.2594 - val_accuracy: 0.6796\nEpoch 18/50\n104/104 [==============================] - 86s 824ms/step - loss: 0.0472 - accuracy: 0.9943 - val_loss: 1.2265 - val_accuracy: 0.6952\nEpoch 19/50\n104/104 [==============================] - 85s 815ms/step - loss: 0.0413 - accuracy: 0.9937 - val_loss: 1.2981 - val_accuracy: 0.6832\nEpoch 20/50\n104/104 [==============================] - 85s 814ms/step - loss: 0.0346 - accuracy: 0.9952 - val_loss: 1.3265 - val_accuracy: 0.6865\nEpoch 21/50\n104/104 [==============================] - 85s 818ms/step - loss: 0.0308 - accuracy: 0.9949 - val_loss: 1.3158 - val_accuracy: 0.6817\nEpoch 22/50\n104/104 [==============================] - 85s 817ms/step - loss: 0.0284 - accuracy: 0.9976 - val_loss: 1.3057 - val_accuracy: 0.6901\nEpoch 23/50\n104/104 [==============================] - 86s 822ms/step - loss: 0.0206 - accuracy: 0.9982 - val_loss: 1.3439 - val_accuracy: 0.6814\nEpoch 24/50\n104/104 [==============================] - 85s 817ms/step - loss: 0.0188 - accuracy: 0.9979 - val_loss: 1.3857 - val_accuracy: 0.6754\nEpoch 25/50\n104/104 [==============================] - 86s 832ms/step - loss: 0.0227 - accuracy: 0.9964 - val_loss: 1.3375 - val_accuracy: 0.6886\nEpoch 26/50\n104/104 [==============================] - 85s 820ms/step - loss: 0.0220 - accuracy: 0.9973 - val_loss: 1.3182 - val_accuracy: 0.6865\nEpoch 27/50\n104/104 [==============================] - 86s 828ms/step - loss: 0.0183 - accuracy: 0.9973 - val_loss: 1.3784 - val_accuracy: 0.6769\nEpoch 28/50\n104/104 [==============================] - 87s 832ms/step - loss: 0.0167 - accuracy: 0.9979 - val_loss: 1.3247 - val_accuracy: 0.6862\nEpoch 29/50\n104/104 [==============================] - 86s 823ms/step - loss: 0.0133 - accuracy: 0.9991 - val_loss: 1.3248 - val_accuracy: 0.6895\nEpoch 30/50\n104/104 [==============================] - 85s 822ms/step - loss: 0.0156 - accuracy: 0.9976 - val_loss: 1.2645 - val_accuracy: 0.6994\nEpoch 31/50\n104/104 [==============================] - 86s 825ms/step - loss: 0.0107 - accuracy: 0.9994 - val_loss: 1.3871 - val_accuracy: 0.6847\nEpoch 32/50\n104/104 [==============================] - 86s 822ms/step - loss: 0.0098 - accuracy: 0.9994 - val_loss: 1.3291 - val_accuracy: 0.7012\nEpoch 33/50\n104/104 [==============================] - 84s 812ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.2696 - val_accuracy: 0.7069\nEpoch 34/50\n104/104 [==============================] - 85s 820ms/step - loss: 0.0087 - accuracy: 0.9991 - val_loss: 1.3073 - val_accuracy: 0.7078\nEpoch 35/50\n104/104 [==============================] - 85s 818ms/step - loss: 0.0096 - accuracy: 0.9991 - val_loss: 1.3014 - val_accuracy: 0.6964\nEpoch 36/50\n104/104 [==============================] - 84s 811ms/step - loss: 0.0082 - accuracy: 0.9994 - val_loss: 1.4264 - val_accuracy: 0.6763\nEpoch 37/50\n104/104 [==============================] - 86s 823ms/step - loss: 0.0073 - accuracy: 0.9994 - val_loss: 1.3003 - val_accuracy: 0.7054\nEpoch 38/50\n104/104 [==============================] - 84s 811ms/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 1.3003 - val_accuracy: 0.7066\nEpoch 39/50\n104/104 [==============================] - 86s 823ms/step - loss: 0.0089 - accuracy: 0.9991 - val_loss: 1.3763 - val_accuracy: 0.6910\nEpoch 40/50\n104/104 [==============================] - 85s 821ms/step - loss: 0.0081 - accuracy: 0.9988 - val_loss: 1.4776 - val_accuracy: 0.6874\nEpoch 41/50\n104/104 [==============================] - 85s 816ms/step - loss: 0.0112 - accuracy: 0.9988 - val_loss: 1.3245 - val_accuracy: 0.6901\nEpoch 42/50\n104/104 [==============================] - 86s 827ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 1.3453 - val_accuracy: 0.7054\nEpoch 43/50\n104/104 [==============================] - 85s 815ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 1.3689 - val_accuracy: 0.6937\nEpoch 44/50\n104/104 [==============================] - 85s 821ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 1.3385 - val_accuracy: 0.6946\nEpoch 45/50\n104/104 [==============================] - 84s 808ms/step - loss: 0.0060 - accuracy: 0.9997 - val_loss: 1.3288 - val_accuracy: 0.7081\nEpoch 46/50\n104/104 [==============================] - 85s 818ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3321 - val_accuracy: 0.7105\nEpoch 47/50\n104/104 [==============================] - 85s 816ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3083 - val_accuracy: 0.7102\nEpoch 48/50\n104/104 [==============================] - 85s 814ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3355 - val_accuracy: 0.7042\nEpoch 49/50\n104/104 [==============================] - 85s 819ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 1.3171 - val_accuracy: 0.7075\nEpoch 50/50\n104/104 [==============================] - 84s 807ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3178 - val_accuracy: 0.7051\n105/105 [==============================] - 37s 353ms/step\nTest accuracy on iterations is  71.43714371437143\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\nprint(classification_report(test.Labels, test.Prediction))","execution_count":14,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.59      0.67      0.63        33\n           1       0.75      0.73      0.74        33\n           2       0.73      0.65      0.69        34\n           3       0.37      0.30      0.33        33\n           4       0.64      0.42      0.51        33\n           5       0.56      0.53      0.55        34\n           6       0.66      0.76      0.70        33\n           7       0.39      0.33      0.36        33\n           8       0.40      0.50      0.44        34\n           9       0.56      0.58      0.57        33\n          10       0.32      0.39      0.35        33\n          11       0.37      0.32      0.34        34\n          12       0.41      0.39      0.40        33\n          13       0.32      0.30      0.31        33\n          14       0.48      0.44      0.46        34\n          15       0.69      0.76      0.72        33\n          16       0.53      0.55      0.54        33\n          17       0.40      0.47      0.43        34\n          18       0.73      0.73      0.73        33\n          19       0.52      0.45      0.48        33\n          20       0.64      0.74      0.68        34\n          21       0.40      0.30      0.34        33\n          22       0.73      0.73      0.73        33\n          23       0.88      0.85      0.87        34\n          24       0.60      0.45      0.52        33\n          25       0.55      0.55      0.55        33\n          26       0.58      0.65      0.61        34\n          27       0.46      0.39      0.43        33\n          28       0.50      0.45      0.48        33\n          29       0.36      0.53      0.43        34\n          30       0.48      0.48      0.48        33\n          31       0.85      0.52      0.64        33\n          32       0.55      0.65      0.59        34\n          33       0.72      0.70      0.71        33\n          34       0.83      0.88      0.85        33\n          35       0.93      0.79      0.86        34\n          36       0.86      0.91      0.88        33\n          38       0.94      0.90      0.92        67\n          39       0.91      0.88      0.89        33\n          40       0.86      0.76      0.81        33\n          41       0.57      0.68      0.62        34\n          42       0.85      0.85      0.85        33\n          43       0.53      0.52      0.52        33\n          44       0.74      0.82      0.78        34\n          45       0.62      0.70      0.66        33\n          46       0.59      0.67      0.63        33\n          50       0.88      0.91      0.89       134\n          51       0.97      0.91      0.94        33\n          52       0.54      0.67      0.59        33\n          53       0.50      0.53      0.51        34\n          54       0.79      0.82      0.81        33\n          55       0.48      0.39      0.43        33\n          56       0.83      0.56      0.67        34\n          57       0.86      0.97      0.91        33\n          58       0.90      0.82      0.86        33\n          59       0.82      0.82      0.82        34\n          60       0.72      0.88      0.79        33\n          61       0.84      0.79      0.81        33\n          62       0.89      0.91      0.90        34\n          63       0.91      0.88      0.89        33\n          64       0.85      0.67      0.75        33\n          65       0.46      0.85      0.60        34\n          66       0.79      0.45      0.58        33\n          67       0.71      0.82      0.76        33\n          69       0.83      0.87      0.85        67\n          70       0.80      0.85      0.82        33\n          71       0.91      0.94      0.93        34\n          72       0.94      0.97      0.96        33\n          73       0.93      0.82      0.87        33\n          75       0.98      0.90      0.94        67\n          78       0.85      0.83      0.84       100\n          79       0.85      0.88      0.87        33\n          81       0.97      0.90      0.93        67\n          82       0.83      0.91      0.87        33\n          83       0.94      0.94      0.94        34\n          84       0.67      0.73      0.70        33\n          85       0.55      0.64      0.59        33\n          86       0.39      0.32      0.35        34\n          87       0.62      0.55      0.58        33\n          88       0.48      0.61      0.53        33\n          89       0.97      0.85      0.91        34\n          90       0.91      0.91      0.91        33\n          91       0.84      0.94      0.89        33\n          92       0.89      0.91      0.90        34\n          94       0.85      0.88      0.87        66\n          95       0.85      0.85      0.85        34\n          96       0.85      0.85      0.85        33\n          97       0.96      0.79      0.87        33\n          98       1.00      0.88      0.94        34\n          99       0.97      0.85      0.90        33\n\n    accuracy                           0.71      3333\n   macro avg       0.70      0.70      0.70      3333\nweighted avg       0.72      0.71      0.71      3333\n\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}