{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, MultiStepLR, ExponentialLR\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.special import binom\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "# files path\n",
    "image_path = \"CUB_200_2011/images\"\n",
    "\n",
    "train = pd.read_csv('PATH/train.csv')\n",
    "test = pd.read_csv('PATH/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUB200(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        label = self.df.Label.values[idx]\n",
    "        filename = self.df.filename.values[idx]\n",
    "        \n",
    "        p_path = os.path.join(image_path, filename)\n",
    "        \n",
    "        image = cv2.imread(p_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = transforms.ToPILImage()(image)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Resize((600, 600)),\n",
    "                                      transforms.RandomCrop((448, 448)),\n",
    "                                      transforms.Resize((448, 448)),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((600, 600)),\n",
    "                                     transforms.CenterCrop((448, 448)),\n",
    "                                     transforms.Resize((448, 448)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "trainset = CUB200(train, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = CUB200(test, transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMargin(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, s=30.0, m1=0.50):\n",
    "        super(ArcMargin, self).__init__()\n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.s = s\n",
    "        self.m1 = m1\n",
    "        self.weight = Parameter(torch.FloatTensor(out_feat, in_feat))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        #---------------------------- Margin Additional -----------------------------\n",
    "        cos_m = math.cos(self.m1)\n",
    "        sin_m = math.sin(self.m1)\n",
    "        th = math.cos(math.pi - self.m1)\n",
    "        mm = math.sin(math.pi - self.m1) * self.m1\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n",
    "        phi = cosine * cos_m - sine * sin_m\n",
    "        phi = torch.where(cosine > th, phi, cosine - mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        one_hot = torch.zeros(cosine.size()).to(device)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  \n",
    "        output *= self.s\n",
    "\n",
    "        return self.s * cosine, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        plane = 512\n",
    "        if model_name == 'resnet50':\n",
    "            backbone = nn.Sequential(*list(models.resnet50(pretrained=pretrained).children())[:-2])\n",
    "            plane = 2048 * 1 * 1\n",
    "        elif model_name == 'resnet101':\n",
    "            backbone = nn.Sequential(*list(models.resnet101(pretrained=pretrained).children())[:-2])\n",
    "            plane = 2048 * 1 * 1\n",
    "        else:\n",
    "            backbone = None\n",
    "        \n",
    "        self.backbone = backbone\n",
    "        self.mpool = nn.AdaptiveMaxPool2d((1, 1))\n",
    "        self.apool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        feat = self.backbone(x)\n",
    "        out = self.mpool(feat)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return out\n",
    "    \n",
    "class Dense(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Dense, self).__init__()\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(2048)\n",
    "        self.fc = nn.Linear(2048, 600)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor):\n",
    "\n",
    "        out = self.fc(self.bn(inputs))\n",
    "        out = nn.ELU(inplace=True)(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "base_lr = 0.01\n",
    "weight_decay = 1e-4\n",
    "num_classes = 200\n",
    "\n",
    "Model = BaseModel('resnet50', pretrained=True).to(device)\n",
    "Dense = Dense().to(device)\n",
    "Arcface = ArcMargin(600, num_classes, s=64, m1=0.5).to(device) # 78.62\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "base_opt = torch.optim.SGD(Model.parameters(), \n",
    "                            lr=lr, \n",
    "                            momentum=0.9,\n",
    "                            weight_decay=weight_decay, \n",
    "                            nesterov=True)\n",
    "\n",
    "optimizer = torch.optim.SGD([{'params': Dense.parameters()}, {'params': Arcface.parameters()}], \n",
    "                            lr=base_lr, \n",
    "                            momentum=0.9,\n",
    "                            weight_decay=weight_decay, \n",
    "                            nesterov=True)\n",
    "\n",
    "# optimization scheduler\n",
    "basesc = torch.optim.lr_scheduler.MultiStepLR(base_opt, milestones=[60], gamma=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[45, 75], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fine-tuning...\n",
      "Epoch 1/100 and used time: 84.10 sec.\n",
      "train loss: 22.3279    train accuracy: 74.5412\n",
      "test loss: 25.3362    test accuracy: 65.8440\n",
      "\n",
      "Epoch 2/100 and used time: 84.11 sec.\n",
      "train loss: 13.9210    train accuracy: 87.1205\n",
      "test loss: 18.3453    test accuracy: 78.0635\n",
      "\n",
      "Epoch 3/100 and used time: 83.99 sec.\n",
      "train loss: 9.7285    train accuracy: 91.9419\n",
      "test loss: 15.4732    test accuracy: 80.9631\n",
      "\n",
      "Epoch 4/100 and used time: 87.22 sec.\n",
      "train loss: 7.0617    train accuracy: 94.8115\n",
      "test loss: 13.9987    test accuracy: 82.8788\n",
      "\n",
      "Epoch 5/100 and used time: 86.78 sec.\n",
      "train loss: 5.7878    train accuracy: 95.7958\n",
      "test loss: 13.9552    test accuracy: 82.6890\n",
      "\n",
      "Epoch 6/100 and used time: 85.86 sec.\n",
      "train loss: 4.3695    train accuracy: 96.8135\n",
      "test loss: 13.1024    test accuracy: 83.2068\n",
      "\n",
      "Epoch 7/100 and used time: 86.07 sec.\n",
      "train loss: 3.4300    train accuracy: 97.5475\n",
      "test loss: 12.8134    test accuracy: 83.4484\n",
      "\n",
      "Epoch 8/100 and used time: 85.80 sec.\n",
      "train loss: 2.3551    train accuracy: 98.5319\n",
      "test loss: 12.1920    test accuracy: 84.2423\n",
      "\n",
      "Epoch 9/100 and used time: 86.02 sec.\n",
      "train loss: 1.8189    train accuracy: 98.9156\n",
      "test loss: 12.1763    test accuracy: 84.4149\n",
      "\n",
      "Epoch 10/100 and used time: 85.41 sec.\n",
      "train loss: 1.0279    train accuracy: 99.4995\n",
      "test loss: 11.6730    test accuracy: 84.5530\n",
      "\n",
      "Epoch 11/100 and used time: 87.64 sec.\n",
      "train loss: 0.7383    train accuracy: 99.6997\n",
      "test loss: 11.6392    test accuracy: 84.5702\n",
      "\n",
      "Epoch 12/100 and used time: 88.30 sec.\n",
      "train loss: 0.6381    train accuracy: 99.7831\n",
      "test loss: 11.6590    test accuracy: 84.8119\n",
      "\n",
      "Epoch 13/100 and used time: 86.64 sec.\n",
      "train loss: 0.4468    train accuracy: 99.8665\n",
      "test loss: 11.4475    test accuracy: 85.0880\n",
      "\n",
      "Epoch 14/100 and used time: 85.52 sec.\n",
      "train loss: 0.3471    train accuracy: 99.8999\n",
      "test loss: 11.4091    test accuracy: 84.3977\n",
      "\n",
      "Epoch 15/100 and used time: 85.73 sec.\n",
      "train loss: 0.2331    train accuracy: 99.9333\n",
      "test loss: 11.4046    test accuracy: 84.7256\n",
      "\n",
      "Epoch 16/100 and used time: 85.08 sec.\n",
      "train loss: 0.2967    train accuracy: 99.8665\n",
      "test loss: 11.3964    test accuracy: 84.3977\n",
      "\n",
      "Epoch 17/100 and used time: 84.94 sec.\n",
      "train loss: 0.2829    train accuracy: 99.8332\n",
      "test loss: 11.3573    test accuracy: 84.9672\n",
      "\n",
      "Epoch 18/100 and used time: 85.33 sec.\n",
      "train loss: 0.1841    train accuracy: 99.9333\n",
      "test loss: 11.2802    test accuracy: 84.7946\n",
      "\n",
      "Epoch 19/100 and used time: 85.33 sec.\n",
      "train loss: 0.1498    train accuracy: 99.9166\n",
      "test loss: 11.1063    test accuracy: 84.9499\n",
      "\n",
      "Epoch 20/100 and used time: 85.01 sec.\n",
      "train loss: 0.1326    train accuracy: 99.9666\n",
      "test loss: 11.0365    test accuracy: 84.9499\n",
      "\n",
      "Epoch 21/100 and used time: 84.86 sec.\n",
      "train loss: 0.1104    train accuracy: 99.9833\n",
      "test loss: 10.7570    test accuracy: 85.6231\n",
      "\n",
      "Epoch 22/100 and used time: 86.02 sec.\n",
      "train loss: 0.0953    train accuracy: 99.9833\n",
      "test loss: 10.9154    test accuracy: 85.2261\n",
      "\n",
      "Epoch 23/100 and used time: 86.52 sec.\n",
      "train loss: 0.0707    train accuracy: 99.9833\n",
      "test loss: 10.8254    test accuracy: 84.7256\n",
      "\n",
      "Epoch 24/100 and used time: 86.10 sec.\n",
      "train loss: 0.0694    train accuracy: 99.9833\n",
      "test loss: 10.8725    test accuracy: 84.7946\n",
      "\n",
      "Epoch 25/100 and used time: 85.58 sec.\n",
      "train loss: 0.0455    train accuracy: 100.0000\n",
      "test loss: 10.7762    test accuracy: 85.5368\n",
      "\n",
      "Epoch 26/100 and used time: 85.65 sec.\n",
      "train loss: 0.0337    train accuracy: 100.0000\n",
      "test loss: 10.9203    test accuracy: 85.0362\n",
      "\n",
      "Epoch 27/100 and used time: 84.90 sec.\n",
      "train loss: 0.0336    train accuracy: 100.0000\n",
      "test loss: 10.6849    test accuracy: 85.5368\n",
      "\n",
      "Epoch 28/100 and used time: 84.74 sec.\n",
      "train loss: 0.0536    train accuracy: 100.0000\n",
      "test loss: 11.1261    test accuracy: 84.5357\n",
      "\n",
      "Epoch 29/100 and used time: 84.68 sec.\n",
      "train loss: 0.0429    train accuracy: 100.0000\n",
      "test loss: 10.8795    test accuracy: 84.7601\n",
      "\n",
      "Epoch 30/100 and used time: 84.58 sec.\n",
      "train loss: 0.0224    train accuracy: 100.0000\n",
      "test loss: 10.7359    test accuracy: 85.3814\n",
      "\n",
      "Epoch 31/100 and used time: 85.04 sec.\n",
      "train loss: 0.0354    train accuracy: 99.9833\n",
      "test loss: 10.8134    test accuracy: 85.0880\n",
      "\n",
      "Epoch 32/100 and used time: 84.58 sec.\n",
      "train loss: 0.0373    train accuracy: 99.9833\n",
      "test loss: 10.6467    test accuracy: 85.0708\n",
      "\n",
      "Epoch 33/100 and used time: 84.81 sec.\n",
      "train loss: 0.0403    train accuracy: 99.9833\n",
      "test loss: 10.9507    test accuracy: 84.8119\n",
      "\n",
      "Epoch 34/100 and used time: 84.79 sec.\n",
      "train loss: 0.0200    train accuracy: 100.0000\n",
      "test loss: 10.7016    test accuracy: 84.7774\n",
      "\n",
      "Epoch 35/100 and used time: 84.82 sec.\n",
      "train loss: 0.0322    train accuracy: 99.9833\n",
      "test loss: 10.8500    test accuracy: 85.0880\n",
      "\n",
      "Epoch 36/100 and used time: 84.34 sec.\n",
      "train loss: 0.0098    train accuracy: 100.0000\n",
      "test loss: 10.4748    test accuracy: 85.2606\n",
      "\n",
      "Epoch 37/100 and used time: 84.07 sec.\n",
      "train loss: 0.0301    train accuracy: 100.0000\n",
      "test loss: 10.6264    test accuracy: 85.3297\n",
      "\n",
      "Epoch 38/100 and used time: 84.71 sec.\n",
      "train loss: 0.0170    train accuracy: 99.9833\n",
      "test loss: 10.5136    test accuracy: 85.3124\n",
      "\n",
      "Epoch 39/100 and used time: 84.93 sec.\n",
      "train loss: 0.0161    train accuracy: 100.0000\n",
      "test loss: 10.6406    test accuracy: 85.2261\n",
      "\n",
      "Epoch 40/100 and used time: 84.54 sec.\n",
      "train loss: 0.0241    train accuracy: 99.9666\n",
      "test loss: 10.7779    test accuracy: 84.9672\n",
      "\n",
      "Epoch 41/100 and used time: 84.95 sec.\n",
      "train loss: 0.0270    train accuracy: 100.0000\n",
      "test loss: 10.8314    test accuracy: 84.4322\n",
      "\n",
      "Epoch 42/100 and used time: 84.53 sec.\n",
      "train loss: 0.0533    train accuracy: 99.9666\n",
      "test loss: 11.0412    test accuracy: 84.7946\n",
      "\n",
      "Epoch 43/100 and used time: 84.68 sec.\n",
      "train loss: 0.0289    train accuracy: 99.9833\n",
      "test loss: 10.7769    test accuracy: 85.0708\n",
      "\n",
      "Epoch 44/100 and used time: 85.35 sec.\n",
      "train loss: 0.0147    train accuracy: 99.9833\n",
      "test loss: 10.7634    test accuracy: 85.1053\n",
      "\n",
      "Epoch 45/100 and used time: 84.96 sec.\n",
      "train loss: 0.0269    train accuracy: 100.0000\n",
      "test loss: 10.8747    test accuracy: 85.3814\n",
      "\n",
      "Epoch 46/100 and used time: 84.82 sec.\n",
      "train loss: 0.0041    train accuracy: 100.0000\n",
      "test loss: 10.4956    test accuracy: 85.4332\n",
      "\n",
      "Epoch 47/100 and used time: 84.93 sec.\n",
      "train loss: 0.0038    train accuracy: 100.0000\n",
      "test loss: 10.3899    test accuracy: 85.5885\n",
      "\n",
      "Epoch 48/100 and used time: 84.62 sec.\n",
      "train loss: 0.0123    train accuracy: 100.0000\n",
      "test loss: 10.5343    test accuracy: 85.5885\n",
      "\n",
      "Epoch 49/100 and used time: 84.67 sec.\n",
      "train loss: 0.0119    train accuracy: 99.9833\n",
      "test loss: 10.3736    test accuracy: 85.6231\n",
      "\n",
      "Epoch 50/100 and used time: 84.91 sec.\n",
      "train loss: 0.0086    train accuracy: 100.0000\n",
      "test loss: 10.3839    test accuracy: 85.7957\n",
      "\n",
      "Epoch 51/100 and used time: 85.04 sec.\n",
      "train loss: 0.0065    train accuracy: 100.0000\n",
      "test loss: 10.1381    test accuracy: 86.1581\n",
      "\n",
      "Epoch 52/100 and used time: 86.18 sec.\n",
      "train loss: 0.0019    train accuracy: 100.0000\n",
      "test loss: 9.9581    test accuracy: 86.2789\n",
      "\n",
      "Epoch 53/100 and used time: 86.32 sec.\n",
      "train loss: 0.0017    train accuracy: 100.0000\n",
      "test loss: 10.2339    test accuracy: 85.9337\n",
      "\n",
      "Epoch 54/100 and used time: 85.10 sec.\n",
      "train loss: 0.0040    train accuracy: 100.0000\n",
      "test loss: 10.2073    test accuracy: 85.9510\n",
      "\n",
      "Epoch 55/100 and used time: 84.59 sec.\n",
      "train loss: 0.0039    train accuracy: 100.0000\n",
      "test loss: 10.1534    test accuracy: 86.2444\n",
      "\n",
      "Epoch 56/100 and used time: 84.92 sec.\n",
      "train loss: 0.0025    train accuracy: 100.0000\n",
      "test loss: 10.2415    test accuracy: 86.2616\n",
      "\n",
      "Epoch 57/100 and used time: 85.66 sec.\n",
      "train loss: 0.0011    train accuracy: 100.0000\n",
      "test loss: 10.1362    test accuracy: 86.3134\n",
      "\n",
      "Epoch 58/100 and used time: 85.10 sec.\n",
      "train loss: 0.0039    train accuracy: 100.0000\n",
      "test loss: 10.1679    test accuracy: 86.3134\n",
      "\n",
      "Epoch 59/100 and used time: 85.09 sec.\n",
      "train loss: 0.0088    train accuracy: 100.0000\n",
      "test loss: 10.3917    test accuracy: 85.9682\n",
      "\n",
      "Epoch 60/100 and used time: 85.18 sec.\n",
      "train loss: 0.0023    train accuracy: 100.0000\n",
      "test loss: 10.2329    test accuracy: 86.0373\n",
      "\n",
      "Epoch 61/100 and used time: 86.77 sec.\n",
      "train loss: 0.0002    train accuracy: 100.0000\n",
      "test loss: 10.1901    test accuracy: 86.1063\n",
      "\n",
      "Epoch 62/100 and used time: 85.52 sec.\n",
      "train loss: 0.0008    train accuracy: 100.0000\n",
      "test loss: 10.1773    test accuracy: 86.2444\n",
      "\n",
      "Epoch 63/100 and used time: 86.58 sec.\n",
      "train loss: 0.0010    train accuracy: 100.0000\n",
      "test loss: 10.0904    test accuracy: 86.2099\n",
      "\n",
      "Epoch 64/100 and used time: 85.93 sec.\n",
      "train loss: 0.0001    train accuracy: 100.0000\n",
      "test loss: 10.0850    test accuracy: 86.2616\n",
      "\n",
      "Epoch 65/100 and used time: 85.52 sec.\n",
      "train loss: 0.0005    train accuracy: 100.0000\n",
      "test loss: 10.0447    test accuracy: 86.1926\n",
      "\n",
      "Epoch 66/100 and used time: 86.88 sec.\n",
      "train loss: 0.0039    train accuracy: 100.0000\n",
      "test loss: 10.0215    test accuracy: 86.5205\n",
      "\n",
      "Epoch 67/100 and used time: 86.36 sec.\n",
      "train loss: 0.0005    train accuracy: 100.0000\n",
      "test loss: 9.9823    test accuracy: 86.3479\n",
      "\n",
      "Epoch 68/100 and used time: 86.01 sec.\n",
      "train loss: 0.0003    train accuracy: 100.0000\n",
      "test loss: 9.9369    test accuracy: 86.5723\n",
      "\n",
      "Epoch 69/100 and used time: 84.76 sec.\n",
      "train loss: 0.0050    train accuracy: 100.0000\n",
      "test loss: 9.9826    test accuracy: 86.4688\n",
      "\n",
      "Epoch 70/100 and used time: 85.23 sec.\n",
      "train loss: 0.0001    train accuracy: 100.0000\n",
      "test loss: 9.9587    test accuracy: 86.5896\n",
      "\n",
      "Epoch 71/100 and used time: 85.15 sec.\n",
      "train loss: 0.0013    train accuracy: 100.0000\n",
      "test loss: 9.9194    test accuracy: 86.4515\n",
      "\n",
      "Epoch 72/100 and used time: 85.48 sec.\n",
      "train loss: 0.0025    train accuracy: 100.0000\n",
      "test loss: 9.9545    test accuracy: 86.4688\n",
      "\n",
      "Epoch 73/100 and used time: 84.82 sec.\n",
      "train loss: 0.0018    train accuracy: 100.0000\n",
      "test loss: 9.9781    test accuracy: 86.3307\n",
      "\n",
      "Epoch 74/100 and used time: 84.51 sec.\n",
      "train loss: 0.0000    train accuracy: 100.0000\n",
      "test loss: 9.8998    test accuracy: 86.6068\n",
      "\n",
      "Epoch 75/100 and used time: 84.94 sec.\n",
      "train loss: 0.0000    train accuracy: 100.0000\n",
      "test loss: 9.8983    test accuracy: 86.6586\n",
      "\n",
      "Epoch 76/100 and used time: 85.10 sec.\n",
      "train loss: 0.0004    train accuracy: 100.0000\n",
      "test loss: 9.8837    test accuracy: 86.6931\n",
      "\n",
      "Epoch 77/100 and used time: 85.39 sec.\n",
      "train loss: 0.0017    train accuracy: 100.0000\n",
      "test loss: 9.8551    test accuracy: 86.5378\n",
      "\n",
      "Epoch 78/100 and used time: 85.30 sec.\n",
      "train loss: 0.0004    train accuracy: 100.0000\n",
      "test loss: 9.8953    test accuracy: 86.3997\n",
      "\n",
      "Epoch 79/100 and used time: 84.76 sec.\n",
      "train loss: 0.0002    train accuracy: 100.0000\n",
      "test loss: 9.8426    test accuracy: 86.3479\n",
      "\n",
      "Epoch 80/100 and used time: 85.18 sec.\n",
      "train loss: 0.0003    train accuracy: 100.0000\n",
      "test loss: 9.8913    test accuracy: 86.5896\n",
      "\n",
      "Epoch 81/100 and used time: 84.52 sec.\n",
      "train loss: 0.0001    train accuracy: 100.0000\n",
      "test loss: 9.8151    test accuracy: 86.7104\n",
      "\n",
      "Epoch 82/100 and used time: 85.14 sec.\n",
      "train loss: 0.0010    train accuracy: 100.0000\n",
      "test loss: 9.8586    test accuracy: 86.3825\n",
      "\n",
      "Epoch 83/100 and used time: 84.74 sec.\n",
      "train loss: 0.0000    train accuracy: 100.0000\n",
      "test loss: 9.8524    test accuracy: 86.5378\n",
      "\n",
      "Epoch 84/100 and used time: 83.98 sec.\n",
      "train loss: 0.0007    train accuracy: 100.0000\n",
      "test loss: 9.7736    test accuracy: 86.9520\n",
      "\n",
      "Epoch 85/100 and used time: 84.04 sec.\n",
      "train loss: 0.0006    train accuracy: 100.0000\n",
      "test loss: 9.8680    test accuracy: 86.7967\n",
      "\n",
      "Epoch 86/100 and used time: 84.74 sec.\n",
      "train loss: 0.0000    train accuracy: 100.0000\n",
      "test loss: 9.7607    test accuracy: 86.6586\n",
      "\n",
      "Epoch 87/100 and used time: 84.67 sec.\n",
      "train loss: 0.0013    train accuracy: 100.0000\n",
      "test loss: 9.7938    test accuracy: 86.5205\n",
      "\n",
      "Epoch 88/100 and used time: 84.43 sec.\n",
      "train loss: 0.0005    train accuracy: 100.0000\n",
      "test loss: 9.7994    test accuracy: 86.5551\n",
      "\n",
      "Epoch 89/100 and used time: 84.60 sec.\n",
      "train loss: 0.0001    train accuracy: 100.0000\n",
      "test loss: 9.7656    test accuracy: 87.0211\n",
      "\n",
      "Epoch 90/100 and used time: 84.61 sec.\n",
      "train loss: 0.0002    train accuracy: 100.0000\n",
      "test loss: 9.8174    test accuracy: 86.7276\n",
      "\n",
      "Epoch 91/100 and used time: 84.83 sec.\n",
      "train loss: 0.0014    train accuracy: 100.0000\n",
      "test loss: 9.7733    test accuracy: 86.9175\n",
      "\n",
      "Epoch 92/100 and used time: 84.52 sec.\n",
      "train loss: 0.0018    train accuracy: 100.0000\n",
      "test loss: 9.7778    test accuracy: 86.7622\n",
      "\n",
      "Epoch 93/100 and used time: 84.42 sec.\n",
      "train loss: 0.0002    train accuracy: 100.0000\n",
      "test loss: 9.7423    test accuracy: 86.9520\n",
      "\n",
      "Epoch 94/100 and used time: 84.98 sec.\n",
      "train loss: 0.0000    train accuracy: 100.0000\n",
      "test loss: 9.7899    test accuracy: 86.6759\n",
      "\n",
      "Epoch 95/100 and used time: 84.61 sec.\n",
      "train loss: 0.0001    train accuracy: 100.0000\n",
      "test loss: 9.7590    test accuracy: 86.6759\n",
      "\n",
      "Epoch 96/100 and used time: 84.61 sec.\n",
      "train loss: 0.0001    train accuracy: 100.0000\n",
      "test loss: 9.7274    test accuracy: 86.7967\n",
      "\n",
      "Epoch 97/100 and used time: 85.38 sec.\n",
      "train loss: 0.0006    train accuracy: 100.0000\n",
      "test loss: 9.7910    test accuracy: 86.7276\n",
      "\n",
      "Epoch 98/100 and used time: 85.00 sec.\n",
      "train loss: 0.0001    train accuracy: 100.0000\n",
      "test loss: 9.7866    test accuracy: 86.8485\n",
      "\n",
      "Epoch 99/100 and used time: 85.31 sec.\n",
      "train loss: 0.0028    train accuracy: 100.0000\n",
      "test loss: 9.7750    test accuracy: 86.6931\n",
      "\n",
      "Epoch 100/100 and used time: 85.91 sec.\n",
      "train loss: 0.0001    train accuracy: 100.0000\n",
      "test loss: 9.7147    test accuracy: 86.7622\n",
      "\n",
      "After the training, the end of the epoch 89, the highest accuracy is 87.02\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "save_model_path = 'Checkpoint'\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "\n",
    "print('Start fine-tuning...')\n",
    "best_acc = 0.\n",
    "best_epoch = None\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        steps += 1\n",
    "        \n",
    "        # Move input and label tensors to the default device\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        base_opt.zero_grad(), optimizer.zero_grad()\n",
    "        \n",
    "        output = Model(inputs)\n",
    "        output = Dense(output)\n",
    "        _, output = Arcface(output, labels)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        base_opt.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    stop_time = time.time()\n",
    "    print('Epoch {}/{} and used time: {:.2f} sec.'.format(epoch, epochs, stop_time - start_time))\n",
    "    \n",
    "    Model.eval(), Arcface.eval(), Dense.eval()\n",
    "    for name, loader in [(\"train\", train_loader), (\"test\", test_loader)]:\n",
    "        _loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in loader:\n",
    "                \n",
    "                imgs, labels = data\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                \n",
    "                output = Model(imgs)\n",
    "                output = Dense(output)\n",
    "                cosine, output = Arcface(output, labels)\n",
    "                loss = criterion(output, labels)\n",
    "                _loss += loss.item()\n",
    "                \n",
    "                result = F.softmax(cosine, dim=1)\n",
    "                _, predicted = torch.max(result, dim=1)\n",
    "                \n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "            _acc = 100 * correct  / total\n",
    "            _loss = _loss / len(loader)\n",
    "            \n",
    "        print('{} loss: {:.4f}    {} accuracy: {:.4f}'.format(name, _loss, name, _acc))\n",
    "    print()\n",
    "    \n",
    "    running_loss = 0\n",
    "    Model.train(), Arcface.train(), Dense.train()\n",
    "    scheduler.step()\n",
    "    basesc.step()\n",
    "    \n",
    "    if _acc > best_acc:\n",
    "        best_acc = _acc\n",
    "        best_epoch = epoch\n",
    "\n",
    "print('After the training, the end of the epoch {}, the highest accuracy is {:.2f}'.format(best_epoch, best_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
