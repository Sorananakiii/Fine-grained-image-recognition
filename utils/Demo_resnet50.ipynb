{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.optim as opt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, MultiStepLR, ExponentialLR\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from skimage import measure\n",
    "from scipy.special import binom\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "# files path\n",
    "image_path = \"CUB_200_2011/images\"\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUB200(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        label = self.df.Label.values[idx]\n",
    "        filename = self.df.filename.values[idx]\n",
    "        \n",
    "        p_path = os.path.join(image_path, filename)\n",
    "        \n",
    "        image = cv2.imread(p_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = transforms.ToPILImage()(image)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "train_transform = transforms.Compose([transforms.Resize((600, 600)),\n",
    "                                      transforms.RandomCrop((448, 448)),\n",
    "                                      transforms.Resize((448, 448)),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((600,600)),\n",
    "                                     transforms.CenterCrop((448, 448)),\n",
    "                                     transforms.Resize((448, 448)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "trainset = CUB200(train, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=24, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = CUB200(test, transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=24, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        # self.conv2 = nn.Conv2d(in_channels=2048, out_channels=2048, kernel_size=4, stride=1,bias=False)\n",
    "        # self.conv3 = nn.Conv2d(in_channels=2048, out_channels=201, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.mpool = nn.AdaptiveMaxPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        conv5_b = self.layer4[:2](x)\n",
    "        x = self.layer4[2](conv5_b)\n",
    "\n",
    "        fm = x\n",
    "        x = self.mpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        embeeding = x\n",
    "\n",
    "        return fm, embeeding, conv5_b\n",
    "\n",
    "\n",
    "def _resnet(arch, block, layers, pretrained, pth_path, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = torch.load(pth_path)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "def resnet50(pth_path, pretrained=False, **kwargs):\n",
    "    r\"\"\"ResNet-50 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, pth_path, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveAM(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, s=30.0, m1=0.50):\n",
    "        super(AdaptiveAM, self).__init__()\n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.s = s\n",
    "        self.m1 = m1\n",
    "        self.weight = Parameter(torch.FloatTensor(out_feat, in_feat))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, input, label, epoch):\n",
    "        #---------------------------- Margin Additional -----------------------------\n",
    "        if epoch <= 20:\n",
    "            m1 = self.m1\n",
    "        elif epoch > 20 and epoch <= 40:\n",
    "            m1 = self.m1 + 0.25\n",
    "        else:\n",
    "            m1 = self.m1 + 0.5\n",
    "        \n",
    "        cos_m, sin_m = math.cos(m1), math.sin(m1)\n",
    "        th = math.cos(math.pi - m1)\n",
    "        mm = math.sin(math.pi - m1) * m1\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n",
    "        phi = cosine * cos_m - sine * sin_m\n",
    "        phi = torch.where(cosine > th, phi, torch.zeros(1).to(device))\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        one_hot = torch.zeros(cosine.size()).to(device)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  \n",
    "        output *= self.s\n",
    "\n",
    "        return self.s * cosine, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AOLM(fms, fm1):\n",
    "    A = torch.sum(fms, dim=1, keepdim=True)\n",
    "    a = torch.mean(A, dim=[2, 3], keepdim=True)\n",
    "    M = (A > a).float()\n",
    "\n",
    "    A1 = torch.sum(fm1, dim=1, keepdim=True)\n",
    "    a1 = torch.mean(A1, dim=[2, 3], keepdim=True)\n",
    "    M1 = (A1 > a1).float()\n",
    "\n",
    "    coordinates = []\n",
    "    for i, m in enumerate(M):\n",
    "        mask_np = m.cpu().numpy().reshape(14, 14)\n",
    "        component_labels = measure.label(mask_np)\n",
    "\n",
    "        properties = measure.regionprops(component_labels)\n",
    "        areas = []\n",
    "        for prop in properties:\n",
    "            areas.append(prop.area)\n",
    "        max_idx = areas.index(max(areas))\n",
    "\n",
    "\n",
    "        intersection = ((component_labels==(max_idx+1)).astype(int) + (M1[i][0].cpu().numpy()==1).astype(int)) ==2\n",
    "        prop = measure.regionprops(intersection.astype(int))\n",
    "        if len(prop) == 0:\n",
    "            bbox = [0, 0, 14, 14]\n",
    "            print('there is one img no intersection')\n",
    "        else:\n",
    "            bbox = prop[0].bbox\n",
    "\n",
    "        x_lefttop = bbox[0] * 32 - 1\n",
    "        y_lefttop = bbox[1] * 32 - 1\n",
    "        x_rightlow = bbox[2] * 32 - 1\n",
    "        y_rightlow = bbox[3] * 32 - 1\n",
    "        # for image\n",
    "        if x_lefttop < 0:\n",
    "            x_lefttop = 0\n",
    "        if y_lefttop < 0:\n",
    "            y_lefttop = 0\n",
    "        coordinate = [x_lefttop, y_lefttop, x_rightlow, y_rightlow]\n",
    "        coordinates.append(coordinate)\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_path = 'resnet50-19c8e357.pth'\n",
    "\n",
    "class MainNet(nn.Module):\n",
    "    def __init__(self, num_classes, channels):\n",
    "        super(MainNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.pretrained_model = resnet50(pretrained=True, pth_path=pretrain_path)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fm, embedding, conv5_b = self.pretrained_model(x)\n",
    "        batch_size, channel_size, side_size, _ = fm.shape\n",
    "        assert channel_size == 2048\n",
    "\n",
    "        #SCDA\n",
    "        coordinates = torch.tensor(AOLM(fm.detach(), conv5_b.detach()))\n",
    "\n",
    "        local_imgs = torch.zeros([batch_size, 3, 448, 448]).to(device)  # [N, 3, 448, 448]\n",
    "        for i in range(batch_size):\n",
    "            [x0, y0, x1, y1] = coordinates[i]\n",
    "            local_imgs[i:i + 1] = F.interpolate(x[i:i + 1, :, x0:(x1+1), y0:(y1+1)], size=(448, 448),\n",
    "                                                mode='bilinear', align_corners=True)  # [N, 3, 224, 224]\n",
    "        local_fm, local_embeddings, _ = self.pretrained_model(local_imgs)  # [N, 2048]\n",
    "\n",
    "        return embedding, local_embeddings\n",
    "    \n",
    "class Dense(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Dense, self).__init__()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(2048)\n",
    "        self.fc1 = nn.Linear(2048, 600)\n",
    "\n",
    "    def forward(self, raw_em, local_em):\n",
    "\n",
    "        raw_em = self.bn1(raw_em)\n",
    "        raw_em = self.fc1(raw_em)\n",
    "        raw_em = nn.ELU(inplace=True)(raw_em)\n",
    "        \n",
    "        local_em = self.bn1(local_em)\n",
    "        local_em = self.fc1(local_em)\n",
    "        local_em = nn.ELU(inplace=True)(local_em)\n",
    "\n",
    "        return raw_em, local_em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_lr = 0.001\n",
    "base_lr = 0.01\n",
    "weight_decay = 1e-4\n",
    "num_classes = 200\n",
    "\n",
    "model = MainNet(num_classes, 2048).to(device)\n",
    "Dense = Dense().to(device)\n",
    "Arcraw = AdaptiveAM(600, num_classes, s=16, m1=0).to(device)\n",
    "Arclocal = AdaptiveAM(600, num_classes, s=16, m1=0).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "Extraction_opt = opt.SGD(model.parameters(), lr=tune_lr, momentum=0.9, weight_decay=weight_decay, nesterov=True)\n",
    "# Extraction_scheduler = ReduceLROnPlateau(Extraction_opt, mode='max', factor=0.1, patience=3, min_lr=1e-5, verbose=True)\n",
    "Dense_opt = opt.SGD([{'params': Dense.parameters()}, {'params': Arcraw.parameters()}, {'params': Arclocal.parameters()}], \n",
    "                    lr=base_lr, \n",
    "                    momentum=0.9, \n",
    "                    weight_decay=weight_decay, \n",
    "                    nesterov=True)\n",
    "\n",
    "Extraction_scheduler = MultiStepLR(Extraction_opt, milestones=[40], gamma=0.1)\n",
    "Dense_scheduler = MultiStepLR(Dense_opt, milestones=[30, 50], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fine-tuning...\n",
      "Epoch 1/70 and used time: 159.24 sec.\n",
      "train loss: 1.8448    train accuracy: 84.1508\n",
      "test loss: 2.3700    test accuracy: 75.1294\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myenv/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/70 and used time: 158.72 sec.\n",
      "train loss: 0.8837    train accuracy: 92.7928\n",
      "test loss: 1.6057    test accuracy: 82.5682\n",
      "\n",
      "Epoch 3/70 and used time: 158.25 sec.\n",
      "train loss: 0.6230    train accuracy: 94.9783\n",
      "test loss: 1.4534    test accuracy: 82.7408\n",
      "\n",
      "Epoch 4/70 and used time: 157.69 sec.\n",
      "train loss: 0.4395    train accuracy: 97.0971\n",
      "test loss: 1.3531    test accuracy: 83.8971\n",
      "\n",
      "there is one img no intersection\n",
      "Epoch 5/70 and used time: 158.43 sec.\n",
      "train loss: 0.3494    train accuracy: 98.2816\n",
      "test loss: 1.3288    test accuracy: 84.4494\n",
      "\n",
      "Epoch 6/70 and used time: 158.63 sec.\n",
      "train loss: 0.2677    train accuracy: 98.6320\n",
      "test loss: 1.2848    test accuracy: 84.2941\n",
      "\n",
      "there is one img no intersection\n",
      "Epoch 7/70 and used time: 158.05 sec.\n",
      "train loss: 0.2084    train accuracy: 99.2659\n",
      "test loss: 1.2567    test accuracy: 84.6048\n",
      "\n",
      "Epoch 8/70 and used time: 157.82 sec.\n",
      "train loss: 0.1849    train accuracy: 99.2826\n",
      "test loss: 1.2479    test accuracy: 84.9499\n",
      "\n",
      "Epoch 9/70 and used time: 158.68 sec.\n",
      "train loss: 0.1600    train accuracy: 99.2659\n",
      "test loss: 1.2208    test accuracy: 85.3124\n",
      "\n",
      "Epoch 10/70 and used time: 158.41 sec.\n",
      "train loss: 0.1306    train accuracy: 99.6997\n",
      "test loss: 1.2225    test accuracy: 85.3469\n",
      "\n",
      "Epoch 11/70 and used time: 159.29 sec.\n",
      "train loss: 0.1199    train accuracy: 99.6663\n",
      "test loss: 1.1919    test accuracy: 85.8647\n",
      "\n",
      "Epoch 12/70 and used time: 158.20 sec.\n",
      "train loss: 0.1036    train accuracy: 99.7664\n",
      "test loss: 1.1840    test accuracy: 85.8474\n",
      "\n",
      "Epoch 13/70 and used time: 158.10 sec.\n",
      "train loss: 0.0915    train accuracy: 99.8332\n",
      "test loss: 1.1701    test accuracy: 85.7957\n",
      "\n",
      "there is one img no intersection\n",
      "Epoch 14/70 and used time: 158.10 sec.\n",
      "train loss: 0.0817    train accuracy: 99.8332\n",
      "test loss: 1.1662    test accuracy: 86.1754\n",
      "\n",
      "Epoch 15/70 and used time: 158.28 sec.\n",
      "train loss: 0.0729    train accuracy: 99.8665\n",
      "test loss: 1.1643    test accuracy: 86.5205\n",
      "\n",
      "Epoch 16/70 and used time: 157.98 sec.\n",
      "train loss: 0.0700    train accuracy: 99.8498\n",
      "test loss: 1.1740    test accuracy: 85.9165\n",
      "\n",
      "there is one img no intersection\n",
      "Epoch 17/70 and used time: 158.02 sec.\n",
      "train loss: 0.0633    train accuracy: 99.8665\n",
      "test loss: 1.1538    test accuracy: 86.5551\n",
      "\n",
      "Epoch 18/70 and used time: 158.73 sec.\n",
      "train loss: 0.0611    train accuracy: 99.8665\n",
      "test loss: 1.1633    test accuracy: 86.3652\n",
      "\n",
      "Epoch 19/70 and used time: 158.17 sec.\n",
      "train loss: 0.0580    train accuracy: 99.8665\n",
      "test loss: 1.1657    test accuracy: 86.0373\n",
      "\n",
      "Epoch 20/70 and used time: 157.66 sec.\n",
      "train loss: 0.0561    train accuracy: 99.8332\n",
      "test loss: 1.1597    test accuracy: 86.4860\n",
      "\n",
      "Epoch 21/70 and used time: 159.18 sec.\n",
      "there is one img no intersection\n",
      "train loss: 0.9289    train accuracy: 99.4494\n",
      "test loss: 4.0081    test accuracy: 84.6220\n",
      "\n",
      "Epoch 22/70 and used time: 159.35 sec.\n",
      "train loss: 0.6093    train accuracy: 99.6496\n",
      "test loss: 3.7147    test accuracy: 85.5885\n",
      "\n",
      "Epoch 23/70 and used time: 158.44 sec.\n",
      "train loss: 0.4582    train accuracy: 99.7164\n",
      "test loss: 3.5927    test accuracy: 86.2616\n",
      "\n",
      "Epoch 24/70 and used time: 158.14 sec.\n",
      "train loss: 0.3378    train accuracy: 99.7664\n",
      "test loss: 3.4762    test accuracy: 86.2616\n",
      "\n",
      "Epoch 25/70 and used time: 159.68 sec.\n",
      "train loss: 0.2758    train accuracy: 99.8665\n",
      "test loss: 3.4392    test accuracy: 86.5551\n",
      "\n",
      "Epoch 26/70 and used time: 158.16 sec.\n",
      "train loss: 0.2262    train accuracy: 99.8665\n",
      "test loss: 3.3714    test accuracy: 86.6241\n",
      "\n",
      "Epoch 27/70 and used time: 157.87 sec.\n",
      "train loss: 0.1982    train accuracy: 99.9499\n",
      "test loss: 3.3762    test accuracy: 86.1581\n",
      "\n",
      "Epoch 28/70 and used time: 159.98 sec.\n",
      "there is one img no intersection\n",
      "train loss: 0.1694    train accuracy: 99.8999\n",
      "test loss: 3.3202    test accuracy: 86.6586\n",
      "\n",
      "Epoch 29/70 and used time: 158.06 sec.\n",
      "train loss: 0.1467    train accuracy: 99.8498\n",
      "test loss: 3.2527    test accuracy: 86.9693\n",
      "\n",
      "Epoch 30/70 and used time: 157.93 sec.\n",
      "train loss: 0.1319    train accuracy: 99.9333\n",
      "test loss: 3.2481    test accuracy: 87.1591\n",
      "\n",
      "Epoch 31/70 and used time: 159.21 sec.\n",
      "train loss: 0.1208    train accuracy: 99.8665\n",
      "test loss: 3.1751    test accuracy: 87.2972\n",
      "\n",
      "Epoch 32/70 and used time: 158.21 sec.\n",
      "train loss: 0.0996    train accuracy: 99.9499\n",
      "test loss: 3.1614    test accuracy: 86.9865\n",
      "\n",
      "Epoch 33/70 and used time: 158.20 sec.\n",
      "train loss: 0.0963    train accuracy: 99.9333\n",
      "test loss: 3.1545    test accuracy: 87.0211\n",
      "\n",
      "Epoch 34/70 and used time: 158.57 sec.\n",
      "train loss: 0.1000    train accuracy: 99.8999\n",
      "test loss: 3.1233    test accuracy: 87.2972\n",
      "\n",
      "there is one img no intersection\n",
      "Epoch 35/70 and used time: 158.13 sec.\n",
      "train loss: 0.0872    train accuracy: 99.9333\n",
      "test loss: 3.0994    test accuracy: 87.6769\n",
      "\n",
      "Epoch 36/70 and used time: 157.89 sec.\n",
      "train loss: 0.0896    train accuracy: 99.9666\n",
      "test loss: 3.0976    test accuracy: 87.2972\n",
      "\n",
      "Epoch 37/70 and used time: 159.19 sec.\n",
      "train loss: 0.0860    train accuracy: 99.9666\n",
      "test loss: 3.1142    test accuracy: 87.4353\n",
      "\n",
      "Epoch 38/70 and used time: 158.18 sec.\n",
      "train loss: 0.0772    train accuracy: 100.0000\n",
      "test loss: 3.0874    test accuracy: 87.7114\n",
      "\n",
      "Epoch 39/70 and used time: 158.02 sec.\n",
      "train loss: 0.0888    train accuracy: 99.8498\n",
      "test loss: 3.1128    test accuracy: 87.3662\n",
      "\n",
      "Epoch 40/70 and used time: 159.24 sec.\n",
      "train loss: 0.0745    train accuracy: 99.9333\n",
      "test loss: 3.0858    test accuracy: 87.2627\n",
      "\n",
      "Epoch 41/70 and used time: 158.05 sec.\n",
      "train loss: 0.9728    train accuracy: 99.9833\n",
      "test loss: 6.8904    test accuracy: 87.5043\n",
      "\n",
      "Epoch 42/70 and used time: 158.18 sec.\n",
      "train loss: 0.8317    train accuracy: 99.9666\n",
      "test loss: 6.7344    test accuracy: 87.4698\n",
      "\n",
      "there is one img no intersection\n",
      "Epoch 43/70 and used time: 157.93 sec.\n",
      "train loss: 0.7084    train accuracy: 99.9333\n",
      "test loss: 6.5715    test accuracy: 87.7287\n",
      "\n",
      "there is one img no intersection\n",
      "Epoch 44/70 and used time: 158.09 sec.\n",
      "train loss: 0.6446    train accuracy: 99.9666\n",
      "test loss: 6.5037    test accuracy: 87.5388\n",
      "\n",
      "Epoch 45/70 and used time: 158.40 sec.\n",
      "train loss: 0.5933    train accuracy: 99.9666\n",
      "test loss: 6.4393    test accuracy: 87.8840\n",
      "\n",
      "Epoch 46/70 and used time: 158.92 sec.\n",
      "train loss: 0.5585    train accuracy: 99.9166\n",
      "test loss: 6.3878    test accuracy: 87.4353\n",
      "\n",
      "Epoch 47/70 and used time: 158.23 sec.\n",
      "train loss: 0.4930    train accuracy: 99.9333\n",
      "test loss: 6.2999    test accuracy: 87.7977\n",
      "\n",
      "Epoch 48/70 and used time: 157.93 sec.\n",
      "train loss: 0.4624    train accuracy: 99.9166\n",
      "test loss: 6.2709    test accuracy: 87.8668\n",
      "\n",
      "Epoch 49/70 and used time: 158.92 sec.\n",
      "train loss: 0.4161    train accuracy: 99.9833\n",
      "test loss: 6.1753    test accuracy: 87.9013\n",
      "\n",
      "Epoch 50/70 and used time: 158.72 sec.\n",
      "train loss: 0.3853    train accuracy: 99.9499\n",
      "test loss: 6.1287    test accuracy: 87.9876\n",
      "\n",
      "there is one img no intersection\n",
      "Epoch 51/70 and used time: 158.04 sec.\n",
      "train loss: 0.3762    train accuracy: 99.9333\n",
      "test loss: 6.1604    test accuracy: 87.5906\n",
      "\n",
      "Epoch 52/70 and used time: 159.07 sec.\n",
      "train loss: 0.3317    train accuracy: 99.9333\n",
      "test loss: 6.0450    test accuracy: 87.8495\n",
      "\n",
      "Epoch 53/70 and used time: 158.58 sec.\n",
      "train loss: 0.3296    train accuracy: 99.9166\n",
      "test loss: 6.0338    test accuracy: 87.5388\n",
      "\n",
      "Epoch 54/70 and used time: 158.25 sec.\n",
      "there is one img no intersection\n",
      "train loss: 0.3051    train accuracy: 99.8832\n",
      "test loss: 5.9710    test accuracy: 87.5388\n",
      "\n",
      "Epoch 55/70 and used time: 158.13 sec.\n",
      "train loss: 0.3155    train accuracy: 99.9333\n",
      "test loss: 5.9916    test accuracy: 88.0739\n",
      "\n",
      "test loss: 5.9720    test accuracy: 87.8322\n",
      "\n",
      "Epoch 57/70 and used time: 158.69 sec.\n",
      "train loss: 0.2827    train accuracy: 99.9166\n",
      "test loss: 5.9203    test accuracy: 88.0221\n",
      "\n",
      "Epoch 58/70 and used time: 158.35 sec.\n",
      "train loss: 0.2655    train accuracy: 99.9666\n",
      "test loss: 5.8723    test accuracy: 88.0739\n",
      "\n",
      "Epoch 59/70 and used time: 157.91 sec.\n",
      "there is one img no intersection\n",
      "train loss: 0.2473    train accuracy: 99.9833\n",
      "test loss: 5.8579    test accuracy: 88.0739\n",
      "\n",
      "Epoch 60/70 and used time: 160.47 sec.\n",
      "train loss: 0.2524    train accuracy: 99.9499\n",
      "test loss: 5.8963    test accuracy: 88.0221\n",
      "\n",
      "Epoch 61/70 and used time: 158.20 sec.\n",
      "train loss: 0.2406    train accuracy: 99.9166\n",
      "test loss: 5.8796    test accuracy: 88.0911\n",
      "\n",
      "Epoch 62/70 and used time: 157.65 sec.\n",
      "train loss: 0.2297    train accuracy: 99.9499\n",
      "test loss: 5.8330    test accuracy: 88.1084\n",
      "\n",
      "Epoch 63/70 and used time: 159.36 sec.\n",
      "train loss: 0.2201    train accuracy: 99.9666\n",
      "test loss: 5.8447    test accuracy: 87.8668\n",
      "\n",
      "Epoch 64/70 and used time: 158.06 sec.\n",
      "train loss: 0.2182    train accuracy: 99.9166\n",
      "test loss: 5.7991    test accuracy: 88.2119\n",
      "\n",
      "Epoch 65/70 and used time: 157.97 sec.\n",
      "train loss: 0.2034    train accuracy: 99.9666\n",
      "test loss: 5.7660    test accuracy: 88.2810\n",
      "\n",
      "Epoch 66/70 and used time: 158.68 sec.\n",
      "train loss: 0.2017    train accuracy: 100.0000\n",
      "test loss: 5.7992    test accuracy: 88.0739\n",
      "\n",
      "Epoch 67/70 and used time: 157.68 sec.\n",
      "train loss: 0.2003    train accuracy: 99.9333\n",
      "test loss: 5.7734    test accuracy: 88.1429\n",
      "\n",
      "Epoch 68/70 and used time: 158.61 sec.\n",
      "train loss: 0.1816    train accuracy: 99.9833\n",
      "test loss: 5.7533    test accuracy: 88.0048\n",
      "\n",
      "Epoch 69/70 and used time: 158.02 sec.\n",
      "train loss: 0.1946    train accuracy: 99.9666\n",
      "test loss: 5.7197    test accuracy: 87.9703\n",
      "\n",
      "Epoch 70/70 and used time: 157.86 sec.\n",
      "train loss: 0.1892    train accuracy: 99.9333\n",
      "test loss: 5.7000    test accuracy: 88.1256\n",
      "\n",
      "After the training, the end of the epoch 65, the highest accuracy is 88.28\n"
     ]
    }
   ],
   "source": [
    "epochs = 70\n",
    "save_model_path = 'Checkpoint'\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "\n",
    "print('Start fine-tuning...')\n",
    "best_acc = 0.\n",
    "best_epoch = None\n",
    "\n",
    "for epoch in range(1, 1+epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        steps += 1\n",
    "        \n",
    "        # Move input and label tensors to the default device\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        Extraction_opt.zero_grad()\n",
    "        Dense_opt.zero_grad()\n",
    "        \n",
    "        raw_em, local_em = model(inputs)\n",
    "        raw_logit, local_logit = Dense(raw_em, local_em)\n",
    "        _, output1 = Arcraw(raw_logit, labels, epoch)\n",
    "        _, output2 = Arclocal(local_logit, labels, epoch)\n",
    "        loss = criterion(output1, labels) + criterion(output2, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        Extraction_opt.step()\n",
    "        Dense_opt.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    stop_time = time.time()\n",
    "    print('Epoch {}/{} and used time: {:.2f} sec.'.format(epoch, epochs, stop_time - start_time))\n",
    "    \n",
    "    model.eval(), Arcraw.eval(), Arclocal.eval(), Dense.eval()\n",
    "    for name, loader in [(\"train\", train_loader), (\"test\", test_loader)]:\n",
    "        _loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in loader:\n",
    "                \n",
    "                imgs, labels = data\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                \n",
    "                raw_em, local_em = model(imgs)\n",
    "                raw_logit, local_logit = Dense(raw_em, local_em)\n",
    "                \n",
    "                _, output1 = Arcraw(raw_logit, labels, epoch)\n",
    "                logit, output2 = Arclocal(local_logit, labels, epoch)\n",
    "                loss = criterion(output1, labels) + criterion(output2, labels)\n",
    "                _loss += loss.item()\n",
    "                \n",
    "                result = F.softmax(logit, dim=1)\n",
    "                _, predicted = torch.max(result, dim=1)\n",
    "                \n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "            _acc = 100 * correct  / total\n",
    "            _loss = _loss / len(loader)\n",
    "            \n",
    "        print('{} loss: {:.4f}    {} accuracy: {:.4f}'.format(name, _loss, name, _acc))\n",
    "    print()\n",
    "    \n",
    "    running_loss = 0\n",
    "    model.train(), Arcraw.train(), Arclocal.train(), Dense.train()\n",
    "    Extraction_scheduler.step(_acc)\n",
    "    Dense_scheduler.step()\n",
    "    \n",
    "    if _acc > best_acc:\n",
    "#         model_file = os.path.join(save_model_path, 'resnet34_CUB_200_fine_tuning_epoch_{}_acc_{}.pth'.format(best_epoch, best_acc))\n",
    "        \n",
    "#         if os.path.isfile(model_file):\n",
    "#             os.remove(os.path.join(save_model_path, 'resnet34_CUB_200_fine_tuning_epoch_{}_acc_{}.pth'.format(best_epoch, best_acc)))\n",
    "        \n",
    "        best_acc = _acc\n",
    "        best_epoch = epoch\n",
    "#         print('The accuracy is improved, save model')\n",
    "#         torch.save(model.state_dict(), os.path.join(save_model_path,'resnet34_CUB_200_fine_tuning_epoch_{}_acc_{}.pth'.format(best_epoch, best_acc)))\n",
    "print('After the training, the end of the epoch {}, the highest accuracy is {:.2f}'.format(best_epoch, best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
